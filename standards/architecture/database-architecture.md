area: database
keyFiles: backend/src/db/schema.ts, backend/src/db/connection.ts, backend/src/db/migrate.ts

# Database Architecture

PostgreSQL serves as the primary relational database. Drizzle ORM handles schema definition, queries, and migrations. Qdrant serves as the vector database for all knowledge collections.

## PostgreSQL Schema

### Users
- `id` (UUID, primary key)
- `username` (unique, 2-50 chars)
- `passwordHash` (bcrypt)
- `role` (enum: user, admin)
- `createdAt`, `updatedAt` (timestamps)

### Conversations
- `id` (UUID, primary key)
- `userId` (FK -> users, cascade delete)
- `title` (text, auto-generated from first message)
- `createdAt`, `updatedAt` (timestamps)
- Composite index on `(userId, updatedAt)` for fast listing

### Messages
- `id` (UUID, primary key)
- `conversationId` (FK -> conversations, cascade delete)
- `role` (enum: user, assistant)
- `content` (text)
- `createdAt` (timestamp)
- Index on `conversationId` for message retrieval

## Connection
- Uses `postgres` driver (not `pg`)
- Connection string from `DATABASE_URL` environment variable
- Drizzle ORM with schema-aware query builder

## Migrations
- Run via `backend/src/db/migrate.ts` using Drizzle's `migrate()` function
- Migration files generated by `drizzle-kit generate` from `schema.ts` (single source of truth)
- Stored in `backend/drizzle/` with journal metadata for version tracking
- Idempotent (safe to run multiple times)

## Vector Storage (Qdrant)

Separate from PostgreSQL. All collections use 1536-dimensional vectors (`text-embedding-3-small` via OpenRouter) with cosine distance.

### Live Collections

| Collection | Content | Key Metadata |
|-----------|---------|-------------|
| `standards` | Team coding conventions and best practices | `title`, `category`, `tags` |
| `code-chunks` | Source code split by language-aware chunking | `filePath`, `language`, `layer`, `startLine`, `endLine` |
| `architecture` | System architecture documentation | `area`, `keyFiles` |
| `schemas` | Database table documentation | `table`, `columns` |
| `reviews` | Nightly code review insights from merge analysis | `severity`, `category`, `filePath`, `commitSha`, `author`, `date` |
| `test-suggestions` | AI-generated test scaffolds from reviewed diffs | `targetFile`, `testType`, `framework`, `commitSha`, `confidence` |

### Planned Collections

| Collection | Content | Key Metadata |
|-----------|---------|-------------|
| `knowledge-gaps` | Under-documented areas detected by nightly analysis | `module`, `reason`, `lastUpdated` |
| `convention-scores` | Convention adherence tracking per merge/module | `module`, `score`, `violations`, `date` |

### Incremental Indexing

The nightly pipeline uses incremental indexing to keep collections fresh:
1. Compare current commit SHA against `tiburcio:codebase-head:{repoName}` in Redis (per-repo)
2. Get list of changed files via `git diff`
3. Delete existing vectors for changed files (prevents stale/duplicate chunks)
4. Chunk, embed, and upsert only the changed files
5. Store new commit SHA in Redis

This avoids re-embedding the entire codebase every night and ensures deleted/renamed files don't leave orphaned vectors.
