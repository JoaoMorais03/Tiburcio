# Database
# IMPORTANT: Password must be URL-safe (no +, /, = characters).
# Generate with: openssl rand -hex 16
DATABASE_URL=postgresql://tiburcio_admin:CHANGE_ME@db:5432/tiburcio_db
POSTGRES_USER=tiburcio_admin
POSTGRES_PASSWORD=CHANGE_ME
POSTGRES_DB=tiburcio_db

# Redis (rate limiting, job queues)
REDIS_URL=redis://redis:6379

# Model provider: "ollama" for local inference, "openrouter" for cloud API
# Ollama = zero external API calls, <3s responses, runs on 32GB RAM
# OpenRouter = cloud-hosted, requires API key, higher quality models
MODEL_PROVIDER=openrouter

# Ollama settings (used when MODEL_PROVIDER=ollama)
# Start Ollama: docker compose --profile ollama up -d
# Pull models: docker exec ollama ollama pull qwen3:8b && docker exec ollama ollama pull nomic-embed-text
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_CHAT_MODEL=qwen3:8b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# OpenRouter settings (used when MODEL_PROVIDER=openrouter)
# Get an API key at https://openrouter.ai
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENROUTER_MODEL=minimax/minimax-m2.5
OPENROUTER_PROVIDER=together
EMBEDDING_MODEL=qwen/qwen3-embedding-8b
EMBEDDING_PROVIDER=nebius

# Embedding vector dimensions (auto-detected from MODEL_PROVIDER if not set)
# 768 for nomic-embed-text (Ollama), 4096 for qwen3-embedding-8b (OpenRouter)
# EMBEDDING_DIMENSIONS=768

# Backend
PORT=3000
NODE_ENV=development

# Authentication
# Must be at least 32 characters. Generate with: openssl rand -base64 32
JWT_SECRET=CHANGE_ME_AT_LEAST_32_CHARACTERS_LONG

# MCP HTTP/SSE transport â€” for shared team deployment.
# When set, exposes MCP tools at /mcp/sse and /mcp/message with Bearer auth.
# Generate with: openssl rand -base64 32
# Claude Code setup:
#   claude mcp add tiburcio --transport sse \
#     --url http://localhost:3000/mcp/sse \
#     --header "Authorization:Bearer <team-api-key>"
# TEAM_API_KEY=your-team-api-key-here

# CORS (comma-separated origins)
CORS_ORIGINS=http://localhost:5173,http://localhost:5174

# Qdrant (vector database)
QDRANT_URL=http://qdrant:6333

# Langfuse (LLM observability)
LANGFUSE_PUBLIC_KEY=pk-lf-local
LANGFUSE_SECRET_KEY=sk-lf-local
LANGFUSE_BASE_URL=http://langfuse:3000

# Langfuse Docker config (used by docker-compose, not by backend)
LANGFUSE_NEXTAUTH_SECRET=langfuse-dev-secret
LANGFUSE_SALT=langfuse-dev-salt
LANGFUSE_ADMIN_PASSWORD=admin123

# Codebase indexing (code search and nightly review)
# Format: name:container-path:branch (comma-separated for multiple repos)
#
# Single repo:
#   CODEBASE_REPOS=myproject:/codebase:develop
#
# Multi-repo (e.g. ProzisHUB with api + ui + batch):
#   CODEBASE_REPOS=api:/codebase/api:develop,ui:/codebase/ui:develop,batch:/codebase/batch:develop
#   Then mount the parent dir in docker-compose.yml:
#     - /host/path/to/ProzisHUB:/codebase:ro
#
# CODEBASE_HOST_PATH is only used by docker-compose.yml for the volume mount.
CODEBASE_HOST_PATH=/path/to/your/project
CODEBASE_REPOS=myproject:/codebase:develop
